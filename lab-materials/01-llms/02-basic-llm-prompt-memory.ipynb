{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## 1.1 - Basic LLM Prompting with vLLM, Langchain and Prompt with Conversation Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.1.9 openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b908fd0-01dd-4ad2-b745-b3a4c56a7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_SERVER_URL = \"https://mistral-7b-instruct-v0-3-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443\"\n",
    "MODEL_NAME = \"mistral-7b-instruct\"\n",
    "API_KEY= os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "#### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211bd1f-3e55-41ce-b3bc-0ee5db689c66",
   "metadata": {},
   "source": [
    "#### Create the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd8bc4c-b353-4a51-a8b7-6cb348e19623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e36542-81a4-4eee-bcf8-f0dd5d9e3096",
   "metadata": {},
   "source": [
    "#### And finally some memory for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0005da7-1386-42a4-9d20-456c5dcca2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory=ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240fd72-f910-4ba4-82dc-c5ebf278452b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First example, fully verbose mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cb39d-1639-4713-8423-4ea4925ef6d1",
   "metadata": {},
   "source": [
    "#### Create the Chain using the different components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7998b5-4373-4b70-bd81-9617f7ff6bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=True,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969484f2-1f55-4021-a995-1d529cf9cc54",
   "metadata": {},
   "source": [
    "#### Let's talk..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI: Paris, the capital of France, is a city renowned for its rich history, art, and culture. Known as the \"City of Light,\" it's famous for iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. The Seine River adds to its romantic charm, while bustling cafes, boutiques, and vibrant nightlife enliven its streets. Paris offers a unique blend of modernity and tradition, making it a must-visit destination for travelers worldwide.\n",
      "Human: Describe Kubeflow in 100 words or less.\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      "Kubeflow is an open-source project that aims to make deploying machine learning (ML) workflows on Kubernetes simple, portable, and scalable. It provides a platform for end-to-end ML pipelines, including data preparation, model training, serving, and management. Kubeflow enables data scientists and engineers to leverage the power of Kubernetes in their ML projects, promoting collaboration and reproducibility across teams.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "first_input = \"Describe Kubeflow in 100 words or less.\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ed6c44-a016-49bd-8623-f231c5bba5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Current conversation:\n",
      "Human: Describe Paris in 100 words or less.\n",
      "AI: Paris, the capital of France, is a city renowned for its rich history, art, and culture. Known as the \"City of Light,\" it's famous for iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. The Seine River adds to its romantic charm, while bustling cafes, boutiques, and vibrant nightlife enliven its streets. Paris offers a unique blend of modernity and tradition, making it a must-visit destination for travelers worldwide.\n",
      "Human: Describe Kubeflow in 100 words or less.\n",
      "AI: Kubeflow is an open-source project that aims to make deploying machine learning (ML) workflows on Kubernetes simple, portable, and scalable. It provides a platform for end-to-end ML pipelines, including data preparation, model training, serving, and management. Kubeflow enables data scientists and engineers to leverage the power of Kubernetes in their ML projects, promoting collaboration and reproducibility across teams.\n",
      "Human: Is there a registry?\n",
      "AI:\n",
      "[/INST]\n",
      "\u001b[0m\n",
      "Yes, there is a Kubeflow Model Hub Registry. It's an open-source platform for discovering, sharing, and deploying pre-trained machine learning models. The registry allows users to find models that have been trained by others, or to share their own models with the community. This promotes collaboration and reproducibility in machine learning projects.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This is a follow-up question without context to showcase the conversation memory\n",
    "second_input = \"Is there a registry?\"\n",
    "conversation.predict(input=second_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dd8b1-c5a1-41fd-8c7f-61e221360753",
   "metadata": {},
   "source": [
    "### Second example, no verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842e0ab2-a061-4ebd-af71-7305c54af940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verbose mode is intentionally set to True so you can see the prompt and the history from the buffer memory\n",
    "conversation2 = ConversationChain(llm=llm,\n",
    "                                 prompt=PROMPT,\n",
    "                                 verbose=False,\n",
    "                                 memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60769ba-dd7a-4ac7-911a-3e0abe9e1732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's clear the previous conversation first\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9113c36-db08-464c-a6a7-e8fdf1068c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update, the latest version of Kubernetes is Kubernetes 1.23, which was released on May 10, 2022. However, it's always a good idea to check the official Kubernetes website for the most recent updates and versions."
     ]
    }
   ],
   "source": [
    "first_input = \"What is the last version of Kubernetes currently?\"\n",
    "conversation2.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d7280-a28f-4cdb-b3de-358200b7f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_input = \"What is then ?\"\n",
    "conversation2.predict(input=first_input);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
