{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## 2.2 - Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5201cd-7664-4cf4-b329-af5aa69a5c76",
   "metadata": {},
   "source": [
    "**Chain of Thought** (CoT) is a concept in natural language processing (NLP) that enables \n",
    "language models to reason through tasks in a structured, step-by-step manner, similar to human \n",
    "thinking. Rather than generating isolated responses, a model using Chain of Thought builds on \n",
    "prior information, creating responses that follow a logical flow and ensuring a coherent, \n",
    "context-aware dialogue. This approach is particularly valuable in complex or multi-step queries,\n",
    "where understanding and maintaining context over multiple interactions is essential.\n",
    "\n",
    "![LLM Tools](../../content/modules/ROOT/assets/images/04/04-02-tools-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ece69d-0255-4232-9f1f-730a54b11453",
   "metadata": {},
   "source": [
    "## Why Chain of Thought Matters\n",
    "\n",
    "In traditional LLM models, responses can sometimes feel disjointed or context-free, especially with complex questions. Chain of Thought addresses these challenges by adding a reasoning layer, allowing the model to generate more accurate and relevant responses. This logical progression offers key benefits:\n",
    "\n",
    "1. **Coherence**: Responses follow a natural flow, making it easier for users to follow and engage with the conversation.\n",
    "2. **Context Retention**: By building on previous information, the model maintains context across multiple steps, crucial for handling complex questions.\n",
    "3. **Increased Accuracy**: Logical progression reduces the likelihood of irrelevant or incorrect information, enhancing the reliability of responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q langchain==0.1.9 openai==1.13.3\n",
    "!pip install -q langchain-openai langchain\n",
    "#!pip uninstall langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "#from langchain_community.llms import VLLMOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b908fd0-01dd-4ad2-b745-b3a4c56a7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_SERVER_URL = \"http://localhost:52892\"\n",
    "MODEL_NAME = \"mistral-7b-instruct\"\n",
    "API_KEY= os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"None\",\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211bd1f-3e55-41ce-b3bc-0ee5db689c66",
   "metadata": {},
   "source": [
    "### Create the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd8bc4c-b353-4a51-a8b7-6cb348e19623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct but in a simple way and very concise\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT_LLM = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f875c62b-931a-402e-9494-98b7296f8b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_LLM,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969484f2-1f55-4021-a995-1d529cf9cc54",
   "metadata": {},
   "source": [
    "### Let's ask a simple question **WITHOUT** Chain of Thought in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To design a financial report based on information from larger Financial Services Institutions (FSIs), you should focus on key performance indicators such as revenue growth, profitability, asset base, capital adequacy ratio, risk management practices, and efficiency ratios. These metrics will help you analyze the financial health and performance of the FSIs and provide valuable insights for your report. Additionally, consider any specific regulations or industry trends that might impact their operations and include relevant data points in your analysis."
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53514c74-27fd-48f7-8f74-dcc96b4856bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM with Chain of Thought in the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ed6c44-a016-49bd-8623-f231c5bba5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful, and honest assistant. Always be as helpful as possible while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "Explain it with bullet points if it's needed but using reasoning and step-by-step.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something incorrect.\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT_COT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06992d19-a605-421b-a560-7082a3f12a6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chain of Thought Prompt\n",
    "\n",
    "Let's ask the same question with Chain of Thought\n",
    "\n",
    "* When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "* Explain it with bullet points if it's needed but using reasoning and step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3dba1b-7d9d-4c1f-b3f2-61b3385f7d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation_cot = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_COT,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98984cb8-b119-4770-a948-2779f211c519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To design a financial report based on a larger Financial Services Institution (FSI) report, consider focusing on the following key areas:\n",
      "\n",
      "1. Understanding the Context: Familiarize yourself with the larger FSI's report to gain an understanding of their business model, objectives, and industry environment. This will help you tailor your financial report to be aligned with their report.\n",
      "\n",
      "2. Relevant Financial Metrics: Identify which key performance indicators (KPIs) from the larger FSI are applicable to your organization. These could include metrics like revenue growth, net profit margin, return on equity, and efficiency ratio.\n",
      "\n",
      "3. Comparison of Financial Statements: Analyze financial statements such as income statement, balance sheet, and cash flow statement. Compare these statements between the larger FSI and your organization to identify trends, differences, and potential areas for improvement.\n",
      "\n",
      "4. Regulatory Compliance: Ensure that you adhere to all relevant regulatory requirements in your industry when preparing your report. This will help maintain transparency and credibility with stakeholders.\n",
      "\n",
      "5. Industry Benchmarking: Use data from the larger FSI as well as industry benchmarks to analyze your performance relative to peers and competitors, helping identify strengths and weaknesses.\n",
      "\n",
      "6. Clear and Concise Presentation: Organize your report in a logical manner using clear, concise language that is easy for readers to understand. Include appropriate charts, graphs, or other visuals to help illustrate data and trends.\n",
      "\n",
      "7. Interpretation of Data: Provide contextualized analysis of financial figures presented in the report, explaining what they mean in terms of your organization's performance, industry context, and future implications. \n",
      "\n",
      "8. Conclusion and Recommendations: Summarize key findings from your analysis and provide recommendations for improving overall financial performance based on trends identified through comparison with the larger FSI."
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation_cot.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c4cad-c8c6-4368-80b9-1cc54195d20d",
   "metadata": {},
   "source": [
    "## Enhancing LLMs Performance with Chain of Thought\n",
    "\n",
    "By simulating a thought process, Chain of Thought enhances NLP models by:\n",
    "\n",
    "- **Improving Context Understanding**: The model remembers previous interactions, generating responses that are relevant and contextually aware.\n",
    "- **Boosting User Experience**: Users benefit from a more natural and satisfying interaction, as the model “thinks” through its responses.\n",
    "- **Increasing Flexibility**: CoT enables models to handle multi-part questions, making them versatile for applications like virtual assistants, customer service bots, and educational tools.\n",
    "\n",
    "Incorporating Chain of Thought into LLMs frameworks, such as LangChain, enables language models to tackle complex tasks, making them more effective for real-world applications where logical reasoning and clarity are paramount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
